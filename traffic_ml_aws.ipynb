{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                  # Pandas\n",
    "import numpy as np                   # Numpy\n",
    "from matplotlib import pyplot as plt # Matplotlib\n",
    "\n",
    "# Package to implement ML Algorithms\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Package for data partitioning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Package for generating confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Package for generating classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import packages to implement Stratified K-fold CV\n",
    "from sklearn.model_selection import KFold # For creating folds\n",
    "\n",
    "# Import Package to implement GridSearch CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Importing package for Randomized Search CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Package to record time\n",
    "import time\n",
    "\n",
    "# Package for Data pretty printer\n",
    "from pprint import pprint\n",
    "\n",
    "# Module to save and load Python objects to and from files\n",
    "import pickle \n",
    "\n",
    "# Ignore Deprecation Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Package for XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Display inline plots as vector-based (svg)\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0     NaN  288.28      0.0      0.0          40       Clouds   \n",
       "1     NaN  289.36      0.0      0.0          75       Clouds   \n",
       "2     NaN  289.58      0.0      0.0          90       Clouds   \n",
       "3     NaN  290.13      0.0      0.0          90       Clouds   \n",
       "4     NaN  291.14      0.0      0.0          75       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0    scattered clouds  2012-10-02 09:00:00            5545  \n",
       "1       broken clouds  2012-10-02 10:00:00            4516  \n",
       "2     overcast clouds  2012-10-02 11:00:00            4767  \n",
       "3     overcast clouds  2012-10-02 12:00:00            5026  \n",
       "4       broken clouds  2012-10-02 13:00:00            4918  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "traffic_df = pd.read_csv('Traffic_Volume.csv')\n",
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the month, day of the week, and time of day from the 'date_time' column\n",
    "traffic_df['month'] = pd.to_datetime(traffic_df['date_time']).dt.month\n",
    "traffic_df['day_of_week'] = pd.to_datetime(traffic_df['date_time']).dt.weekday\n",
    "traffic_df['time_of_day'] = pd.to_datetime(traffic_df['date_time']).dt.strftime('%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['traffic_volume'].value_counts(normalize=True)\n",
    "X = traffic_df.drop(columns = ['traffic_volume','weather_description','date_time'])\n",
    "y = traffic_df['traffic_volume']\n",
    "\n",
    "cat_var = ['holiday', 'weather_main','month','day_of_week','time_of_day']\n",
    "X_encoded = pd.get_dummies(X, columns = cat_var)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_encoded, y, test_size = 0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Training time: 14.426593542098999s\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "regressor = DecisionTreeRegressor(random_state = 2)\n",
    "\n",
    "# Ranges for hyperparameters\n",
    "hyper_params = {\n",
    "    'max_depth': list(range(2, 23)),\n",
    "    'min_samples_leaf': list(range(2, 23)),\n",
    "    'min_samples_split': list(range(2, 23))\n",
    "}\n",
    "\n",
    "# Creating folds\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 3)\n",
    "\n",
    "# Create the random search CV\n",
    "random_model_cv = RandomizedSearchCV(estimator = regressor,\n",
    "                                     param_distributions = hyper_params,\n",
    "                                     scoring = 'r2',\n",
    "                                     cv = folds,\n",
    "                                     verbose = 1,\n",
    "                                     n_jobs = -1,\n",
    "                                     n_iter = 50,\n",
    "                                     random_state = 4)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "random_model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 20, 'min_samples_leaf': 20, 'max_depth': 22}\n",
      "0.9350860381837002\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(random_model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(random_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_new = {\n",
    "    'max_depth': list(range(20,24)),\n",
    "    'min_samples_leaf': list(range(18, 22)),\n",
    "    'min_samples_split': list(range(18, 22))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Training time: 18.6946120262146s\n"
     ]
    }
   ],
   "source": [
    "model_cv = GridSearchCV(estimator = regressor,\n",
    "                        param_grid = hyper_params_new,\n",
    "                        scoring = 'r2',\n",
    "                        cv = folds,\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 23, 'min_samples_leaf': 20, 'min_samples_split': 18}\n",
      "0.9362238956938794\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_new = {\n",
    "    'max_depth': list(range(18,23)),\n",
    "    'min_samples_leaf': list(range(18, 22)),\n",
    "    'min_samples_split': list(range(18, 22))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Training time: 21.452025413513184s\n"
     ]
    }
   ],
   "source": [
    "model_cv = GridSearchCV(estimator = regressor,\n",
    "                        param_grid = hyper_params_new,\n",
    "                        scoring = 'r2',\n",
    "                        cv = folds,\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 22, 'min_samples_leaf': 20, 'min_samples_split': 18}\n",
      "0.9350860381837002\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=22, min_samples_leaf=20, min_samples_split=18,\n",
      "                      random_state=2)\n"
     ]
    }
   ],
   "source": [
    "bestClassTree = model_cv.best_estimator_\n",
    "print(bestClassTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test set\n",
    "y_pred = model_cv.predict(test_X)\n",
    "\n",
    "score = model_cv.score(train_X, train_y)\n",
    "print('R-squared:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
      " 'min_samples_leaf': [5, 10, 20],\n",
      " 'min_samples_split': [5, 10, 20],\n",
      " 'n_estimators': [50, 87, 125, 162, 200]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 20]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [5, 10, 20]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\OneDrive\\Documents\\FALL 2023 CLASSES\\IME 565\\VScode\\Midterm\\traffic_ml.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/OneDrive/Documents/FALL%202023%20CLASSES/IME%20565/VScode/Midterm/traffic_ml.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/OneDrive/Documents/FALL%202023%20CLASSES/IME%20565/VScode/Midterm/traffic_ml.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()            \u001b[39m# Start Time\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/OneDrive/Documents/FALL%202023%20CLASSES/IME%20565/VScode/Midterm/traffic_ml.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m random_model_cv\u001b[39m.\u001b[39mfit(train_X, train_y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/OneDrive/Documents/FALL%202023%20CLASSES/IME%20565/VScode/Midterm/traffic_ml.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()             \u001b[39m# End Time\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/OneDrive/Documents/FALL%202023%20CLASSES/IME%20565/VScode/Midterm/traffic_ml.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining time: \u001b[39m\u001b[39m{\u001b[39;00mstop\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1807\u001b[0m         ParameterSampler(\n\u001b[0;32m   1808\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_distributions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter, random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state\n\u001b[0;32m   1809\u001b[0m         )\n\u001b[0;32m   1810\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "regressor2 = RandomForestRegressor(random_state = 2)\n",
    "\n",
    "# Creating folds\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 3)\n",
    "\n",
    "# Create the random search CV\n",
    "random_model_cv = RandomizedSearchCV(estimator = regressor2,\n",
    "                                     param_distributions = random_grid,\n",
    "                                     scoring = 'r2',\n",
    "                                     cv = folds,\n",
    "                                     verbose = 1,\n",
    "                                     n_jobs = -1,\n",
    "                                     n_iter = 100,\n",
    "                                     random_state = 4)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "random_model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 125, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_depth': 20}\n",
      "0.9372444442042221\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(random_model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(random_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_new = {\n",
    "    'max_depth': list(range(18,22)),\n",
    "    'min_samples_leaf': list(range(3, 7)),\n",
    "    'min_samples_split': list(range(8, 12)),\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Training time: 3803.5792903900146s\n"
     ]
    }
   ],
   "source": [
    "model_cv = GridSearchCV(estimator = regressor2,\n",
    "                        param_grid = hyper_params_new,\n",
    "                        scoring = 'r2',\n",
    "                        cv = folds,\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 21, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 150}\n",
      "0.9394524035310349\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=21, min_samples_leaf=4, min_samples_split=8,\n",
      "                      n_estimators=150, random_state=2)\n"
     ]
    }
   ],
   "source": [
    "bestForest = model_cv.best_estimator_\n",
    "print(bestForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.949814338235056\n"
     ]
    }
   ],
   "source": [
    "# predictions on test set\n",
    "y_pred = model_cv.predict(test_X)\n",
    "\n",
    "score2 = model_cv.score(train_X, train_y)\n",
    "print('R-squared:', score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor3 = AdaBoostRegressor(random_state = 2)\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Training time: 1533.051924943924s\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "regressor3 = AdaBoostRegressor(random_state = 2)\n",
    "\n",
    "hyper_params = {\n",
    "    'n_estimators': [50, 100, 250, 500],\n",
    "    'learning_rate': np.linspace(0.01,1,10),\n",
    "    'base_estimator': [DecisionTreeRegressor(max_depth=depth) for depth in range (1,11)],\n",
    "    'loss': ['linear','square','exponential']\n",
    "}\n",
    "\n",
    "# Create the random search CV\n",
    "random_model_cv = RandomizedSearchCV(estimator = regressor3,\n",
    "                                     param_distributions=hyper_params,\n",
    "                                     scoring = 'r2',\n",
    "                                     cv = folds,\n",
    "                                     verbose = 1,\n",
    "                                     n_jobs = -1,\n",
    "                                     n_iter = 50,\n",
    "                                     random_state = 4)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "random_model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'loss': 'linear', 'learning_rate': 0.01, 'base_estimator': DecisionTreeRegressor(max_depth=9)}\n",
      "0.7901486742306124\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(random_model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(random_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_new = {\n",
    "    'n_estimators': [500, 600],\n",
    "    'learning_rate': [0.01,0.02],\n",
    "    'base_estimator': [DecisionTreeRegressor(max_depth=9)],\n",
    "    'loss': ['linear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Training time: 634.939924955368s\n"
     ]
    }
   ],
   "source": [
    "model_cv = GridSearchCV(estimator = regressor3,\n",
    "                        param_grid = hyper_params_new,\n",
    "                        scoring = 'r2',\n",
    "                        cv = folds,\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': DecisionTreeRegressor(max_depth=9), 'learning_rate': 0.02, 'loss': 'linear', 'n_estimators': 500}\n",
      "0.8110256425652735\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=9),\n",
      "                  learning_rate=0.02, n_estimators=500, random_state=2)\n"
     ]
    }
   ],
   "source": [
    "bestAda = model_cv.best_estimator_\n",
    "print(bestAda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.8142486179669973\n"
     ]
    }
   ],
   "source": [
    "# predictions on test set\n",
    "y_pred = model_cv.predict(test_X)\n",
    "\n",
    "score3 = model_cv.score(train_X, train_y)\n",
    "print('R-squared:', score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'n_estimators': np.arange(50, 200, 10),\n",
    "    'max_depth': np.arange(3, 10),\n",
    "    'subsample': np.linspace(0.5, 1.0, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 6),\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0, 1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Training time: 458.6381824016571s\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "regressor4 = XGBRegressor(random_state = 2)\n",
    "\n",
    "# Create the random search CV\n",
    "random_model_cv = RandomizedSearchCV(estimator = regressor4,\n",
    "                                     param_distributions=hyper_params,\n",
    "                                     scoring = 'r2',\n",
    "                                     cv = folds,\n",
    "                                     verbose = 1,\n",
    "                                     n_jobs = -1,\n",
    "                                     n_iter = 50,\n",
    "                                     random_state = 4)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "random_model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.6, 'reg_lambda': 5, 'reg_alpha': 0, 'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.10666666666666666, 'gamma': 1, 'colsample_bytree': 1.0}\n",
      "0.9505377004861815\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(random_model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(random_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_new = {\n",
    "    'learning_rate': [0.1,0.11],\n",
    "    'n_estimators': [170],\n",
    "    'max_depth': list(range(8, 10)),\n",
    "    'subsample': [0.6],\n",
    "    'colsample_bytree': [0.9,1],\n",
    "    'gamma': [0.9,1],\n",
    "    'reg_alpha': [0],\n",
    "    'reg_lambda': [4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Training time: 63.117436170578s\n"
     ]
    }
   ],
   "source": [
    "model_cv = GridSearchCV(estimator = regressor4,\n",
    "                        param_grid = hyper_params_new,\n",
    "                        scoring = 'r2',\n",
    "                        cv = folds,\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "model_cv.fit(train_X, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.11, 'max_depth': 9, 'n_estimators': 170, 'reg_alpha': 0, 'reg_lambda': 5, 'subsample': 0.6}\n",
      "0.9504632343679171\n"
     ]
    }
   ],
   "source": [
    "# Return set of parameters with the best performance\n",
    "print(model_cv.best_params_)\n",
    "\n",
    "# Return the performance metric score\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=1, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.11, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=170, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=2, ...)\n"
     ]
    }
   ],
   "source": [
    "bestXGB = model_cv.best_estimator_\n",
    "print(bestXGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9705382457031485\n"
     ]
    }
   ],
   "source": [
    "# predictions on test set\n",
    "y_pred = model_cv.predict(test_X)\n",
    "\n",
    "score4 = model_cv.score(train_X, train_y)\n",
    "print('R-squared:', score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file where we want to write the model\n",
    "dt_pickle = open('decision_tree_traffic.pickle', 'wb') \n",
    "rf_pickle = open('rf_traffic.pickle','wb')\n",
    "ada_pickle = open('ada_traffic.pickle','wb')\n",
    "xgb_pickle = open('xgb_traffic.pickle','wb')\n",
    "\n",
    "# Write DT model to the file\n",
    "pickle.dump(bestClassTree, dt_pickle) \n",
    "pickle.dump(bestForest,rf_pickle)\n",
    "pickle.dump(bestAda,ada_pickle)\n",
    "pickle.dump(bestXGB,xgb_pickle)\n",
    "\n",
    "# Close the file\n",
    "dt_pickle.close() \n",
    "rf_pickle.close()\n",
    "ada_pickle.close()\n",
    "xgb_pickle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
